beta
song1 <- paste(a, b)
song1
song2 <- c(a, b)
song2
length(song1)
length(song2)
1:4
seq(1, 4, 1)
seq(1, 10, 2)
onethrufour <- 1:4
onethrufour
val1 <- 1
val2 <- "a"
val3 <- TRUE
mode(val1)
mode(val2)
mode(val3)
9 < "Cow"
"9" < "Cow"
"ABC" < "ABB"
"ABC" < "ABD"
"9" < "Cow"
9 < "Cow"
1 + "Hippo"
val1 + val2
c(val1, val2)
val1 + val3
val1 == val3
a <- c(val1, val3)
b <- c(val1, val3, val2)
a
b
c(a, val2)
keepvalues <- list()
keepvalues
keepvalues$a <- val1
keepvalues$b <- val2
keepvalues$c <- val3
keepvalues
keepvalues[[1]]
keepvalues[[2]]
keepvalues[[3]]
keepvalues[[1]] == a[1]
keepvalues[[1]] == "1"
ls()
rm(a)
rm(b)
ls()
list = ls()
list
rm(list = ls())
ls()
x <- c(1, 2, 5, 8, 10)
y <- c(5, 5, 5, 3, 9)
cbind(x, y)
z <- rbind(x, y, y, y)
z
x + y
x / y
x * y
x
length(x)
log(x)
max(x)
which.min(x)
x[1]
x[2]
x[c(3, 4)]
x[c(TRUE,TRUE,FALSE,FALSE,TRUE)]
x[c(1,1,0,0,1)]
z
dim(z)
z[1, 2]
z[1, ]
z[, 3]
z[2:3, ]
z[2:3, 1:4]
z[1:3, 1:3] <- 24601
z
our.data <- data.frame(alpha = c(1, 2, 4, 5)) # give it the first column
our.data
our.data$beta <- c(3, 4, 3, 4)
our.data
our.data$gamma <- c("q", "wer", "ty", " ")
our.data
our.data$lambda <- c(1, 2)
our.data
our.data$lambda <- 1
our.data
n <- 100000
normals <- rnorm(n, 0, 1)
length(normals)
normals[1:100]
mode(normals)
roundnormals <- round(normals, 3)
roundnormals[1:100]
round(normals, 3)[1:100]
runif(5)
runif(5)
beforerng <- .Random.seed
runif(5)
afterrng <- .Random.seed
rbind(beforerng, afterrng)
.Random.seed
beforerng <- .Random.seed
beforerng
runif(5)
afterrng <- .Random.seed
rbind(beforerng, afterrng)
afterrng - beforerng
table(afterrng - beforerng)
beforerng <- .Random.seed
runif(4)
afterrng <- .Random.seed
table(afterrng - beforerng)
?.Random.seed
?runif
set.seed(beforerng)
runif(4)
set.seed(beforerng)
runif(4)
set.seed(beforerng)
runif(4)
set.seed(123)
.Random.seed
runif(4)
set.seed(123)
runif(4)
combinations <- combn(5, 3)
?combn
combinations
dim(combinations)
combn
dim(combn)
c(combn, combn)
runif
rnorm
myfunction <- function(x) {
xtemp <- x + 1
return(xtemp)
}
myfunction
myfunction(0)
# Can iterate the same function over and over.
avector <- c(1,2,8,-10)
avector
avector <- myfunction(avector)
avector
avector <- myfunction(avector)
avector
avector <- myfunction(avector)
avector
listoffunctions <- list()
listoffunctions$a <- myfunction
listoffunctions$a
listoffunctions$a(1)
listoffunctions$a(3079)
?ifelse
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
head(Boston)
?Boston
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
head(Boston)
?Boston
plot(Boston[,c(14, 1, 7, 11, 13)])
m1 <- lm(medv ~ lstat, data=Boston)
summary(m1)
resid(m1)
hist(resid(m1))
qqnorm(resid(m1))
plot(resid(m1) ~ fitted(m1))
m2 <- lm(medv ~ log(lstat), data=Boston)
qqnorm(resid(m2))
plot(resid(m2) ~ fitted(m2))
summary(m2)
m3 <- lm(medv ~ log(lstat) + age, data=Boston)
summary(m3)
m4 <- lm(medv ~ . -lstat + log(lstat), data=Boston)
summary(m4)
?Boston
set.seed(123) # IMPORTANT!
?sample
1:nrow(Boston)
s <- sample(1:nrow(Boston), nrow(Boston)/2, replace = FALSE)
s
-s
test <- Boston[-s,] # Anything other than the s set
train <- Boston[s,]
f1 <- fitted(m1)
f1
cor(fitted(m1), train$medv)^2
m1 <- lm(medv ~ log(lstat) + age, data=train)
summary(m1)
f1 <- fitted(m1)
f1
cor(fitted(m1), train$medv)^2
p1 <- predict(m1, newdata=train)
head(f1)
head(p1)
identical(f1, p1)
sum(abs(f1-p1))
m2 <- lm(medv ~ tax + log(lstat) + age, data=train)
summary(m2)
hist(train$tax)
train$taxlvl <- cut(train$tax, breaks = c(0, 300, 600, 1000))
test$taxlvl <- cut(test$tax, breaks = c(0, 300, 600, 1000))
levels(train$taxlvl)
levels(test$taxlvl)
levels(test$tax)
levels(test$taxlvl)
contrasts(train$taxlvl)
m3 <- lm(medv ~ taxlvl + log(lstat) + age, data=train)
levels(test$taxlvl)
class(test$tax)
class(test$taxlvl)
m3 <- lm(medv ~ taxlvl + log(lstat) + age, data=train) # Regions with higher taxes tend to lowere housing values
summary(m3)
contrasts(train$taxlvl)
anova(m3)
m3 <- lm(medv ~ taxlvl + log(lstat) + age, data=train) # Regions with higher taxes tend to lowere housing values
summary(m3)
anova(m3) # To get single p-values for single variables
m4 <- lm(medv ~ taxlvl * log(lstat) + age, data=train)
summary(m4)
anova(m4)
anova(m3, m4)
anova(m2, m4) # not nested, no warning message! don't interpret results
anova(m1, m4)
test
p1 <- predict(m1, newdata=test) # predictions for unseen data
p2 <- predict(m2, newdata=test) # predictions for unseen data
p3 <- predict(m3, newdata=test) # predictions for unseen data
p4 <- predict(m4, newdata=test) # predictions for unseen data
mean((p1-test$medv)^2)
mean((p2-test$medv)^2)
mean((p3-test$medv)^2)
mean((p4-test$medv)^2)
qnorm(0.8)
qnorm(0.95)
qnorm(0.975)
(1.96+0.84)^2
log(0.2231)/log(0.3679)
log(0.3679)/log(0.2231)
2.779/0.979
2.997/0.979
0.6734/(0.6734+0.2767)
library(dplyr)
library(dplyr)
library(bis557)
install()
install.packages("devtools")
install.packages("devtools")
library(devtools)
install()
install.packages("BiocManager")
library(BiocManager)
install()
library(bis557)
install()
a <- c(1,2,3,4)
a
a[2]
a[2] = 1
a
a == 1
sum(a == 1)
sum(a)
which(a == 1)
which(a == 4)
length(a)
class(2)
class(TRUE)
class(a)
class(2018-09-12)
devtools::install()
library(devtools)
devtools::install()
setwd("~/Documents/Master2-2/BIS 557-Computational Statistics/bis557")
install.packages("ggplot2")
library(devtools)
devtools::install()
library(bis557)
library(dplyr)
data("ridge_train")
data("ridge_test")
#lambdas <- seq(10^-5, 10^5, 1000)
#log.lambdas <- log(lambdas, base = 10)
log.lambdas <- seq(-5, 5, 0.1)
lambdas <- 10^log.lambdas
?nest()
library(tidyr)
install.packages("tidyr")
knitr::opts_chunk$set(echo = TRUE)
library(tidyr)
?nest
formula <- y ~. - 1
lambda <- 1.2
data <- ridge_train
fit_ridge <- ridge_reg(formula, lambda, data)
data.train <- ridge_train
data.test <- ridge_test
beta <- fit_ridge$coef
?tcrossprod
y_hat <- tcrossprod(ridge_test, beta)
x_test <- model.matrix(formula, ridge_test)
head(x_test)
y_hat <- tcrossprod(x_test, beta)
dim(x_test)
dim(beta)
beta <- fit_ridge$coef
y_hat <- tcrossprod(x_test, beta)
length(beta)
y_hat <- tcrossprod(x_test, beta)
#y_hat <- tcrossprod(x_test, beta)
y_hat <- x_test %*% beta
y_test <- matrix(data[,as.character(formula)[2]], ncol=1)
y_test <- matrix(data.test[,as.character(formula)[2]], ncol=1)
y_test
y_test <- y_test[as.numeric(rownames(x_test)),, drop=FALSE]
mse <- mean((y_hat - y_test)^2)
sapply(lambdas, function(lambda) ridge_mse(formula, lambda, data.train, data.test))
ridge_mse <- function(formula, lambda, data.train, data.test) {
fit_ridge <- ridge_reg(formula, lambda, data.train)
beta <- fit_ridge$coef
x_test <- model.matrix(formula, ridge_test)
y_test <- matrix(data.test[,as.character(formula)[2]], ncol=1)
y_test <- y_test[as.numeric(rownames(x_test)),, drop=FALSE]
#y_hat <- tcrossprod(x_test, beta)
y_hat <- x_test %*% beta
mse <- mean((y_hat - y_test)^2)
}
sapply(lambdas, function(lambda) ridge_mse(formula, lambda, data.train, data.test))
mses <- sapply(lambdas, function(lambda) ridge_mse(formula, lambda, data.train, data.test))
plot(lambdas, mses)
formula
plot(log.lambdas, mses)
plot(log.lambdas, mses)
# Find lambda that minimize MSE
which.min(mses)
# Find lambda that minimize MSE
mses[which.min(mses)]
plot(log.lambdas, mses)
# Find lambda that minimize MSE
lambdas[which.min(mses)]
# Find lambda that minimize MSE
log.lambdas[which.min(mses)]
lambdas[which.min(mses)]
plot(log.lambdas, mses)
which.min(mses)
mses
log.lambdas
# Find lambda that minimize MSE
log.lambdas[which.min(mses)]
# Find lambda that minimize MSE
min.log.lambda <- log.lambdas[which.min(mses)]
min.lambda <- lambdas[which.min(mses)]
# Zoom in lambda
seq(min.lambda - 2, min.lambda + 2, 0.01)
lambdas
# Zoom in lambda
seq(min.lambda - 2, min.lambda + 2, 0.05)
# Zoom in lambda
seq(min.lambda - 2.5, min.lambda + 2.5, 0.05)
# Zoom in lambda
new.log.lambdas <- seq(min.lambda - 2.5, min.lambda + 2.5, 0.05)
new.lambdas <- 10^new.log.lambdas
# Calculate MSE for each lambda
new.mses <- sapply(new.lambdas,
function(lambda)
ridge_mse(y ~ . - 1, lambda, ridge_train, ridge_test))
# Plot MSE against each log(lambda) value
plot(new.log.lambdas, new.mses)
new.log.lambdas
# Zoom in lambda
new.log.lambdas <- seq(min.log.lambda - 2.5, min.log.lambda + 2.5, 0.05)
new.log.lambdas
new.lambdas <- 10^new.log.lambdas
# Calculate MSE for each lambda
new.mses <- sapply(new.lambdas,
function(lambda)
ridge_mse(y ~ . - 1, lambda, ridge_train, ridge_test))
# Plot MSE against each log(lambda) value
plot(new.log.lambdas, new.mses)
# Find lambda that minimize MSE
min.new.log.lambda <- new.log.lambdas[which.min(new.mses)]
min.new.log.lambda
min.new.lambda <- new.lambdas[which.min(new.mses)]
mses
new.mses
new.log.lambdas
log.lambdas
# Zoom in lambda
new.log.lambdas <- seq(min.log.lambda - 1, min.log.lambda + 1, 0.01)
new.log.lambdas
# Zoom in lambda
new.log.lambdas <- seq(min.log.lambda - 1, min.log.lambda + 1, 0.02)
new.log.lambdas
new.lambdas <- 10^new.log.lambdas
# Calculate MSE for each lambda
new.mses <- sapply(new.lambdas,
function(lambda)
ridge_mse(y ~ . - 1, lambda, ridge_train, ridge_test))
# Plot MSE against each log(lambda) value
plot(new.log.lambdas, new.mses)
# Find lambda that minimize MSE
min.new.log.lambda <- new.log.lambdas[which.min(new.mses)]
min.new.log.lambda
# Zoom in lambda
new.log.lambdas <- seq(min.log.lambda - 0.5, min.log.lambda + 0.5, 0.01)
new.log.lambdas
new.lambdas <- 10^new.log.lambdas
# Calculate MSE for each lambda
new.mses <- sapply(new.lambdas,
function(lambda)
ridge_mse(y ~ . - 1, lambda, ridge_train, ridge_test))
# Plot MSE against each log(lambda) value
plot(new.log.lambdas, new.mses)
# Find lambda that minimize MSE
min.new.log.lambda <- new.log.lambdas[which.min(new.mses)]
min.new.log.lambda
min.new.lambda <- new.lambdas[which.min(new.mses)]
min.new.lambda
test()
check()
install.packages("knitr")
check()
install.packages(rmarkdown)
install.packages("rmarkdown")
check()
library(dplyr)
library(MASS)
install.packages("MASS")
install.packages("ROCR")
check()
setwd("~/Documents/Master2-2/BIS 557-Computational Statistics/bis557")
library(devtools)
check()
?plot
?seq
check()
lm_patho <- read.csv("df.csv")
dir.create("../data")
save(lm_patho, file = "../data/lm_patho.rda")
setwd("~/Documents/Master2-2/BIS 557-Computational Statistics/bis557/data-raw")
lm_patho <- read.csv("df.csv")
dir.create("../data")
save(lm_patho, file = "../data/lm_patho.rda")
lm_patho <- read.csv("ridge_test.csv")
save(lm_patho, file = "../data/ridge_test.rda")
lm_patho <- read.csv("ridge_train.csv")
save(lm_patho, file = "../data/ridge_train.rda")
check()
setwd("~/Documents/Master2-2/BIS 557-Computational Statistics/bis557")
check()
getwd()
namespaceExport()
test()
check()
install()
check()
load("/Users/Dandelion/Documents/Master2-2/BIS 557-Computational Statistics/bis557/data/ridge_test.rda")
load("/Users/Dandelion/Documents/Master2-2/BIS 557-Computational Statistics/bis557/data/ridge_train.rda")
load("/Users/Dandelion/Documents/Master2-2/BIS 557-Computational Statistics/bis557/data/lm_patho.rda")
test()
check()
test()
install()
test()
check()
stencila:::start(authorization=FALSE)
install.packages("stencila")
stencila:::start(authorization=FALSE)
devtools::install("stencila")
stencila:::start(authorization=FALSE)
install()
test()
lm_patho <- read.csv("df.csv")
save(lm_patho, file = "../data/lm_patho.rda")
setwd("~/Documents/Master2-2/BIS 557-Computational Statistics/bis557/data-raw")
install()
test()
check()
pnorm(-0.5)
1 - pnorm(-0.5)
qnorm(1-0.04)
pnorm(0.38)
1 - pnorm(0.38)
qnorm(0.9)
qnorm(0.99)
pnorm(-0.5)
1 - pnorm(-0.5)
pnorm(1-0.04)
qnorm(1-0.04)
pnorm(0.38)
qnorm(0.9)
qnorm(0.01)
pnorm(-0.5)
lambda_vals <- seq(0, nrow(x_test*2, length.out = N)
)
seq(0, nrow(x_test*2), length.out = N)
seq(0, nrow(x_test*2), length.out = 500)
setwd("~/Documents/Master2-2/BIS 557-Computational Statistics/bis557")
install()
dim(data.train)
x <- model.matrix(y ~ . - 1, ridge_train)
svd(x)
svdx <- svd(x)
svdx$d
svdx$d^2
