m2 <- lm(medv ~ tax + log(lstat) + age, data=train)
summary(m2)
hist(train$tax)
train$taxlvl <- cut(train$tax, breaks = c(0, 300, 600, 1000))
test$taxlvl <- cut(test$tax, breaks = c(0, 300, 600, 1000))
levels(train$taxlvl)
levels(test$taxlvl)
levels(test$tax)
levels(test$taxlvl)
contrasts(train$taxlvl)
m3 <- lm(medv ~ taxlvl + log(lstat) + age, data=train)
levels(test$taxlvl)
class(test$tax)
class(test$taxlvl)
m3 <- lm(medv ~ taxlvl + log(lstat) + age, data=train) # Regions with higher taxes tend to lowere housing values
summary(m3)
contrasts(train$taxlvl)
anova(m3)
m3 <- lm(medv ~ taxlvl + log(lstat) + age, data=train) # Regions with higher taxes tend to lowere housing values
summary(m3)
anova(m3) # To get single p-values for single variables
m4 <- lm(medv ~ taxlvl * log(lstat) + age, data=train)
summary(m4)
anova(m4)
anova(m3, m4)
anova(m2, m4) # not nested, no warning message! don't interpret results
anova(m1, m4)
test
p1 <- predict(m1, newdata=test) # predictions for unseen data
p2 <- predict(m2, newdata=test) # predictions for unseen data
p3 <- predict(m3, newdata=test) # predictions for unseen data
p4 <- predict(m4, newdata=test) # predictions for unseen data
mean((p1-test$medv)^2)
mean((p2-test$medv)^2)
mean((p3-test$medv)^2)
mean((p4-test$medv)^2)
qnorm(0.8)
qnorm(0.95)
qnorm(0.975)
(1.96+0.84)^2
log(0.2231)/log(0.3679)
log(0.3679)/log(0.2231)
2.779/0.979
2.997/0.979
0.6734/(0.6734+0.2767)
setwd("~/Documents/Master2-2/BIS 557-Computational Statistics/homework 1/bis557")
check()
library(devtools)
check()
check()
check()
check()
data("lm_patho")
setwd("~/Documents/Master2-2/BIS 557-Computational Statistics/bis557")
data("lm_patho")
lm_patho
data("ridge_test")
setwd("~/Documents/Master2-2/BIS 557-Computational Statistics/bis557/data")
data("ridge_test")
data(ridge_test)
setwd("~/Documents/Master2-2/BIS 557-Computational Statistics/bis557")
data("ridge_train")
data("ridge_test")
data("ridge_train")
head(ridge_test)
head(ridge_train)
data("ridge_train")
getwd
getwd()
check()
check()
check()
check()
check()
?lm
?read.csv
?save
?dir.create
?read.csv
sum(dbinom(1:6, 6, 1/6)
ï¼‰
sum(dbinom(1:6, 6, 1/6))
sum(dbinom(0:6, 6, 1/6))
ridge_reg <- function(formula, data, lambda = 1.2121212) {
rownames(data) <- NULL
m <- model.matrix(formula, data)
y <- matrix(data[,as.character(formula)[2]], ncol=1)
y <- y[as.numeric(rownames(m)),, drop=FALSE]
k <- ncol(m)
# Using svd
svd_obj <- svd(m)
U <- svd_obj$u
V <- svd_obj$v
svals <- svd_obj$d
D <- diag(svals / (svals^2 + lambda))
beta <-V %*% D %*% t(U) %*% y
rownames(beta) <- colnames(m)
# Using Baysien
#beta <- solve(crossprod(m) + diag(lambda, ncol(m)), crossprod(m, y))
# Principle Component
#svd_obj <- svd(m)
#U <- svd_obj$u
#V <- svd_obj$v
#dvals <- rep(0, ncol(m))
#dvals[seq_len(k)] <- 1 / svd_obj[["d"]][seq_len(k)]
#D <- diag(dvals)
#beta <- V %*% D %*% t(U) %*% y
# Format coef for export
coef <- beta[2:k]
names(coef) <- colnames(m[,-1])
ret <- list(coef = coef, lambda = lambda, form = form)
class(ret) <- "ridge_reg"
ret
}
fit_ridge <- ridge_reg(y ~. - 1, lambda, ridge_train_scale)
lambda <- 1.2121212
fit_ridge <- ridge_reg(y ~. - 1, lambda, ridge_train_scale)
ridge_train
ridge_train_scale <- as.data.frame(scale(ridge_train))
fit_ridge <- ridge_reg(y ~. - 1, lambda, ridge_train_scale)
#' @description This function passes parameters to the lm function.
#' @param formula a formula
#' @param data a data.frame
#' @param lambda a numeric parameter
#' @return An ridge_reg object
#' @import stats
#' @examples
#' fit <- ridge_reg(Sepal.Length ~., iris, 1.2)
#' summary(fit)
#' @export
ridge_reg <- function(formula, lambda = 1.2121212, data) {
rownames(data) <- NULL
m <- model.matrix(formula, data)
y <- matrix(data[,as.character(formula)[2]], ncol=1)
y <- y[as.numeric(rownames(m)),, drop=FALSE]
k <- ncol(m)
# Using svd
svd_obj <- svd(m)
U <- svd_obj$u
V <- svd_obj$v
svals <- svd_obj$d
D <- diag(svals / (svals^2 + lambda))
beta <-V %*% D %*% t(U) %*% y
rownames(beta) <- colnames(m)
# Using Baysien
#beta <- solve(crossprod(m) + diag(lambda, ncol(m)), crossprod(m, y))
# Principle Component
#svd_obj <- svd(m)
#U <- svd_obj$u
#V <- svd_obj$v
#dvals <- rep(0, ncol(m))
#dvals[seq_len(k)] <- 1 / svd_obj[["d"]][seq_len(k)]
#D <- diag(dvals)
#beta <- V %*% D %*% t(U) %*% y
# Format coef for export
coef <- beta[2:k]
names(coef) <- colnames(m[,-1])
ret <- list(coef = coef, lambda = lambda, form = form)
class(ret) <- "ridge_reg"
ret
}
fit_ridge <- ridge_reg(y ~. - 1, lambda, ridge_train_scale)
y ~. - 1
lambda
fit_lm.ridge <- MASS::lm.ridge(y ~., ridge_train, lambda = 1.2121212)
#' @description This function passes parameters to the lm function.
#' @param formula a formula
#' @param data a data.frame
#' @param lambda a numeric parameter
#' @return An ridge_reg object
#' @import stats
#' @examples
#' fit <- ridge_reg(Sepal.Length ~., iris, 1.2)
#' summary(fit)
#' @export
ridge_reg <- function(formula, lambda = 1.2121212, data) {
rownames(data) <- NULL
m <- model.matrix(formula, data)
y <- matrix(data[,as.character(formula)[2]], ncol=1)
y <- y[as.numeric(rownames(m)),, drop=FALSE]
k <- ncol(m)
# Using svd
svd_obj <- svd(m)
U <- svd_obj$u
V <- svd_obj$v
svals <- svd_obj$d
D <- diag(svals / (svals^2 + lambda))
beta <-V %*% D %*% t(U) %*% y
rownames(beta) <- colnames(m)
# Using Baysien
#beta <- solve(crossprod(m) + diag(lambda, ncol(m)), crossprod(m, y))
# Principle Component
#svd_obj <- svd(m)
#U <- svd_obj$u
#V <- svd_obj$v
#dvals <- rep(0, ncol(m))
#dvals[seq_len(k)] <- 1 / svd_obj[["d"]][seq_len(k)]
#D <- diag(dvals)
#beta <- V %*% D %*% t(U) %*% y
# Format coef for export
coef <- beta[2:k]
names(coef) <- colnames(m[,-1])
ret <- list(coef = coef, lambda = lambda, formula = formula)
class(ret) <- "ridge_reg"
ret
}
fit_ridge <- ridge_reg(y ~. - 1, lambda, ridge_train_scale)
fit_ridge$coef
#' @description This function passes parameters to the lm function.
#' @param formula a formula
#' @param data a data.frame
#' @param lambda a numeric parameter
#' @return An ridge_reg object
#' @import stats
#' @examples
#' fit <- ridge_reg(Sepal.Length ~., iris, 1.2)
#' summary(fit)
#' @export
ridge_reg <- function(formula, lambda = 1.2121212, data) {
rownames(data) <- NULL
m <- model.matrix(formula, data)
y <- matrix(data[,as.character(formula)[2]], ncol=1)
y <- y[as.numeric(rownames(m)),, drop=FALSE]
k <- ncol(m)
# Using svd
svd_obj <- svd(m)
U <- svd_obj$u
V <- svd_obj$v
svals <- svd_obj$d
D <- diag(svals / (svals^2 + lambda))
beta <-V %*% D %*% t(U) %*% y
rownames(beta) <- colnames(m)
# Using Baysien
#beta <- solve(crossprod(m) + diag(lambda, ncol(m)), crossprod(m, y))
# Principle Component
#svd_obj <- svd(m)
#U <- svd_obj$u
#V <- svd_obj$v
#dvals <- rep(0, ncol(m))
#dvals[seq_len(k)] <- 1 / svd_obj[["d"]][seq_len(k)]
#D <- diag(dvals)
#beta <- V %*% D %*% t(U) %*% y
# Format coef for export
#coef <- beta[2:k]
#names(coef) <- colnames(m[,-1])
names(coef) <- colnames(m)
ret <- list(coef = coef, lambda = lambda, formula = formula)
class(ret) <- "ridge_reg"
ret
}
fit_ridge$coef
fit_ridge <- ridge_reg(y ~. - 1, lambda, ridge_train_scale)
fit_ridge <- ridge_reg(y ~. - 1, lambda, ridge_train_scale)
#' @description This function passes parameters to the lm function.
#' @param formula a formula
#' @param data a data.frame
#' @param lambda a numeric parameter
#' @return An ridge_reg object
#' @import stats
#' @examples
#' fit <- ridge_reg(Sepal.Length ~., iris, 1.2)
#' summary(fit)
#' @export
ridge_reg <- function(formula, lambda = 1.2121212, data) {
rownames(data) <- NULL
m <- model.matrix(formula, data)
y <- matrix(data[,as.character(formula)[2]], ncol=1)
y <- y[as.numeric(rownames(m)),, drop=FALSE]
k <- ncol(m)
# Using svd
svd_obj <- svd(m)
U <- svd_obj$u
V <- svd_obj$v
svals <- svd_obj$d
D <- diag(svals / (svals^2 + lambda))
beta <-V %*% D %*% t(U) %*% y
rownames(beta) <- colnames(m)
# Using Baysien
#beta <- solve(crossprod(m) + diag(lambda, ncol(m)), crossprod(m, y))
# Principle Component
#svd_obj <- svd(m)
#U <- svd_obj$u
#V <- svd_obj$v
#dvals <- rep(0, ncol(m))
#dvals[seq_len(k)] <- 1 / svd_obj[["d"]][seq_len(k)]
#D <- diag(dvals)
#beta <- V %*% D %*% t(U) %*% y
# Format coef for export
#coef <- beta[2:k]
#names(coef) <- colnames(m[,-1])
coef <- beta
names(coef) <- colnames(m)
ret <- list(coef = coef, lambda = lambda, formula = formula)
class(ret) <- "ridge_reg"
ret
}
fit_ridge <- ridge_reg(y ~. - 1, lambda, ridge_train_scale)
fit_ridge$coef
test()
test()
fit <- ridge_reg(Sepal.Length ~., iris)
fit <- ridge_reg(Sepal.Length ~., 1.2,iris)
#'
#' @description This function performs a ridge regression.
#' @param formula a formula
#' @param data a data.frame
#' @param lambda a numeric parameter
#' @return An ridge_reg object
#' @import stats MASS
#' @examples
#' fit <- ridge_reg(Sepal.Length ~., 1.2, iris)
#' @export
ridge_reg <- function(formula, lambda, data) {
rownames(data) <- NULL
m <- model.matrix(formula, data)
y <- matrix(data[,as.character(formula)[2]], ncol=1)
y <- y[as.numeric(rownames(m)),, drop=FALSE]
# Using svd
svd_obj <- svd(m)
U <- svd_obj$u
V <- svd_obj$v
svals <- svd_obj$d
D <- diag(svals / (svals^2 + lambda))
beta <-V %*% D %*% t(U) %*% y
rownames(beta) <- colnames(m)
# Format coef for export
coef <- beta
names(coef) <- colnames(m)
# The object to export
ret <- list(coef = coef, lambda = lambda, formula = formula)
class(ret) <- "ridge_reg"
ret
}
lambda <- 1.2121212
ridge_train_scale <- as.data.frame(scale(ridge_train))
fit_ridge <- ridge_reg(y ~. - 1, lambda, ridge_train_scale)
fit_ridge$coef
#'
#' @description This function performs a ridge regression.
#' @param formula a formula
#' @param data a data.frame
#' @param lambda a numeric parameter
#' @return An ridge_reg object
#' @import stats MASS
#' @examples
#' fit <- ridge_reg(Sepal.Length ~., 1.2, iris)
#' @export
ridge_reg <- function(formula, lambda, data) {
rownames(data) <- NULL
m <- model.matrix(formula, data)
y <- matrix(data[,as.character(formula)[2]], ncol=1)
y <- y[as.numeric(rownames(m)),, drop=FALSE]
# Using svd
svd_obj <- svd(m)
U <- svd_obj$u
V <- svd_obj$v
svals <- svd_obj$d
D <- diag(svals / (svals^2 + lambda))
beta <-V %*% D %*% t(U) %*% y
rownames(beta) <- colnames(m)
# Format coef for export
coef <- as.numeric(beta)
names(coef) <- colnames(m)
# The object to export
ret <- list(coef = coef, lambda = lambda, formula = formula)
class(ret) <- "ridge_reg"
ret
}
lambda <- 1.2121212
ridge_train_scale <- as.data.frame(scale(ridge_train))
fit_ridge <- ridge_reg(y ~. - 1, lambda, ridge_train_scale)
fit_ridge$coef
test()
?svd
?diag
check()
?ecdf
library(glmnet)
library(Matrix)
library(foreach)
knitr::opts_chunk$set(echo = TRUE)
n <- 200
x <- seq(0,1,length.out = n)
y_bar <- sin(x * 3 * pi) + cos(x * 5 * pi) + x^2
y <- y_bar + rnorm(n, sd = 0.25)
x_test <- sort(unif(n))
n <- 200
x <- seq(0,1,length.out = n)
y_bar <- sin(x * 3 * pi) + cos(x * 5 * pi) + x^2
y <- y_bar + rnorm(n, sd = 0.25)
x_test <- sort(runif(n))
y_bar <- sin(x_test * 3 * pi) + cos(x_test * 5 * pi) + x_test^2
y_test <- y_bar + rnorm(n, sd = 0.25)
d <- tibble(x = x, y = y)
n <- 200
x <- seq(0,1,length.out = n)
y_bar <- sin(x * 3 * pi) + cos(x * 5 * pi) + x^2
y <- y_bar + rnorm(n, sd = 0.25)
x_test <- sort(runif(n))
y_bar <- sin(x_test * 3 * pi) + cos(x_test * 5 * pi) + x_test^2
y_test <- y_bar + rnorm(n, sd = 0.25)
n <- 200
x <- seq(0,1,length.out = n)
y_bar <- sin(x * 3 * pi) + cos(x * 5 * pi) + x^2
y <- y_bar + rnorm(n, sd = 0.25)
x_test <- sort(runif(n))
y_bar <- sin(x_test * 3 * pi) + cos(x_test * 5 * pi) + x_test^2
y_test <- y_bar + rnorm(n, sd = 0.25)
d <- tibble(x = x, y = y)
library(tibble)
library(ggplot2)
library(dplyr)
d <- tibble(x = x, y = y)
d$x2 <- d$x^2
d$x3 <- d$x^3
fit <- lm(y ~ (x + 1)^3, d)
fit <- lm(y ~ (x + x2 + x3)^3, d)
d$fitted <- fit$fitted.values
d$x4 <- d$x^4
d$x5 <- d$x^5
fit <- lm(y ~ (x + x2 + x3 + x4 + x5)^3, d)
d$fitted <- fit$fitted.values
ggplot(d, aes(x = x, y = y)) + geom_point() + geom_line(aes(x = x, y = fitted))
# Does it look orthomormal?
crossprod(poly_5)
x <- c(0, 1:10)
poly_5 <- poly(x, n = 5)
# Does it look orthomormal?
crossprod(poly_5)
x <- c(0, 1:10)
poly_5 <- poly(x, n = 5)
# Does it look orthomormal?
crossprod(poly_5)
x_new <- runif(100)
poly_5_new <- predict(poly_5, x_new)
# Is it orthonormal for the new data?
crossprod(poly_5_new)
n
x
y_bar
?predict
poly_5
# Is it orthonormal for the new data?
crossprod(poly_5_new)
?poly
###
cbind(1, x, x2, x3)
###
cbind(x, x2, x3)
###
cbind(1, d$x, d$x2, d$x3)
###
X <- cbind(1, d$x, d$x2, d$x3)
crossprod(X)
svdx <- svd(X)
crossprod(X %*% svdx$v)
install()
library(bis557)
ridge_reg
data("ridge_train")
data("ridge_test")
lambdas <- seq(10^-5, 10^5, 100)
lambdas
length(lambda)
length(lambdas)
lambdas <- seq(10^-5, 10^5, 1000)
length(lambdas)
lambdas <- seq(10^-5, 10^5, 1000)
log.lambdas <- log(lambdas)
log.lambdas
log.lambdas <- log(lambdas, base = 10)
log.lambdas
#lambdas <- seq(10^-5, 10^5, 1000)
#log.lambdas <- log(lambdas, base = 10)
log.lambdas <- seq(-5, 5, 0.1)
#lambdas <- seq(10^-5, 10^5, 1000)
#log.lambdas <- log(lambdas, base = 10)
log.lambdas <- seq(-5, 5, 0.1)
lambdas <- 10^log.lambdas
library(dplyr)
library(dplyr)
library(dplyr)
install()
library(dplyr)
test()
library(dplyr)
library(dplyr)
library(tibble)
install.packages("dplyr")
library(dplyr)
devtools::install_github("r-lib/rlang", build_vignettes = TRUE)
library(dplyr)
versin
version
remotes::install_github()
install.packages("remote")
remotes::install_github()
library(remote)
remotes::install_github()
install.packages("remotes")
library(remotes)
remotes::install_github()
remotes::install_local()
getwd()
remotes::install_local("/Users/Dandelion/Documents/Master2-2/BIS 557-Computational Statistics/bis557")
library(dplyr)
update.packages()
library(dplyr)
library(bis557)
library(dplyr)
library(dplyr)
library(dplyr)
